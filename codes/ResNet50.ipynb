{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc8e5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os, numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564c99cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.13)\n",
      "Path to dataset files: C:\\Users\\Begad\\.cache\\kagglehub\\datasets\\asdasdasasdas\\garbage-classification\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "#Download & Load Dataset\n",
    "path = kagglehub.dataset_download(\"asdasdasasdas/garbage-classification\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataset_path = \"C:/Users/Begad/.cache/kagglehub/datasets/asdasdasasdas/garbage-classification/versions/2\"\n",
    "img_path = os.path.join(dataset_path, \"Garbage classification\", \"Garbage classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f533e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 6 classes\n",
      "cardboard: 403 images\n",
      "glass: 501 images\n",
      "metal: 410 images\n",
      "paper: 594 images\n",
      "plastic: 482 images\n",
      "trash: 137 images\n",
      "Total Images are: 2527\n"
     ]
    }
   ],
   "source": [
    "# Dataset Overview\n",
    "classes = os.listdir(img_path)\n",
    "num_classes = len(classes)\n",
    "print(f\"We have {num_classes} classes\")\n",
    "\n",
    "total_images = 0\n",
    "for c in classes:\n",
    "    images = os.listdir(os.path.join(img_path, c))\n",
    "    total_images += len(images)\n",
    "    print(f\"{c}: {len(images)} images\")\n",
    "\n",
    "print(f\"Total Images are: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ef4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Generators with Strong Augmentation\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    img_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    img_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f45810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Weights for Imbalance\n",
    "y_train = train_generator.classes\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e48d6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7a893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 Base Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers:\n",
    "    if 'conv4' in layer.name or 'conv5' in layer.name:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8372a415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,146,950\n",
      "Trainable params: 22,643,334\n",
      "Non-trainable params: 1,503,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Custom Classification Head\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0778fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e9f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # watch validation loss\n",
    "    factor=0.5,           # reduce LR by half\n",
    "    patience=3,           # wait 3 epochs before reducing\n",
    "    min_lr=1e-7,          # never go below this\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06831ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 29s 392ms/step - loss: 2.1127 - accuracy: 0.2470 - val_loss: 1.4508 - val_accuracy: 0.4473 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 1.6151 - accuracy: 0.4224 - val_loss: 1.3016 - val_accuracy: 0.5288 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 25s 388ms/step - loss: 1.3432 - accuracy: 0.5375 - val_loss: 1.1987 - val_accuracy: 0.6083 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 26s 402ms/step - loss: 1.1787 - accuracy: 0.6299 - val_loss: 1.0791 - val_accuracy: 0.6879 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 26s 398ms/step - loss: 0.9873 - accuracy: 0.7312 - val_loss: 1.0371 - val_accuracy: 0.7237 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 25s 397ms/step - loss: 0.9177 - accuracy: 0.7678 - val_loss: 0.9580 - val_accuracy: 0.7455 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 25s 397ms/step - loss: 0.8327 - accuracy: 0.8231 - val_loss: 0.9290 - val_accuracy: 0.7734 - lr: 1.0000e-05\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.7638 - accuracy: 0.8567 - val_loss: 0.9415 - val_accuracy: 0.7793 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 25s 397ms/step - loss: 0.7427 - accuracy: 0.8602 - val_loss: 0.8538 - val_accuracy: 0.8012 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.7148 - accuracy: 0.8888 - val_loss: 0.8130 - val_accuracy: 0.8290 - lr: 1.0000e-05\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 25s 402ms/step - loss: 0.6908 - accuracy: 0.9007 - val_loss: 0.8592 - val_accuracy: 0.8231 - lr: 1.0000e-05\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.6578 - accuracy: 0.9076 - val_loss: 0.7755 - val_accuracy: 0.8489 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.6434 - accuracy: 0.9224 - val_loss: 0.7986 - val_accuracy: 0.8410 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.6220 - accuracy: 0.9348 - val_loss: 0.8150 - val_accuracy: 0.8370 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.6065 - accuracy: 0.9338 - val_loss: 0.7649 - val_accuracy: 0.8529 - lr: 1.0000e-05\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.5925 - accuracy: 0.9447 - val_loss: 0.8318 - val_accuracy: 0.8429 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 25s 397ms/step - loss: 0.5883 - accuracy: 0.9496 - val_loss: 0.7829 - val_accuracy: 0.8449 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.9595\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.5693 - accuracy: 0.9595 - val_loss: 0.7710 - val_accuracy: 0.8608 - lr: 1.0000e-05\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.5603 - accuracy: 0.9629 - val_loss: 0.7238 - val_accuracy: 0.8708 - lr: 5.0000e-06\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 25s 397ms/step - loss: 0.5521 - accuracy: 0.9708 - val_loss: 0.7390 - val_accuracy: 0.8648 - lr: 5.0000e-06\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.5465 - accuracy: 0.9753 - val_loss: 0.7334 - val_accuracy: 0.8767 - lr: 5.0000e-06\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.9694\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "64/64 [==============================] - 25s 391ms/step - loss: 0.5420 - accuracy: 0.9694 - val_loss: 0.7507 - val_accuracy: 0.8549 - lr: 5.0000e-06\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 25s 397ms/step - loss: 0.5418 - accuracy: 0.9773 - val_loss: 0.7581 - val_accuracy: 0.8648 - lr: 2.5000e-06\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 26s 405ms/step - loss: 0.5370 - accuracy: 0.9743 - val_loss: 0.7465 - val_accuracy: 0.8549 - lr: 2.5000e-06\n"
     ]
    }
   ],
   "source": [
    "# Train with scheduler\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop, lr_scheduler],   # add here\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b173866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-Tuning: Unfreeze deeper layers\n",
    "for layer in base_model.layers:\n",
    "    if 'conv4' in layer.name or 'conv5' in layer.name:\n",
    "        layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa8c844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 29s 400ms/step - loss: 0.1653 - accuracy: 0.9590 - val_loss: 0.3874 - val_accuracy: 0.8668\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.1101 - accuracy: 0.9738 - val_loss: 0.4679 - val_accuracy: 0.8549\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.0943 - accuracy: 0.9778 - val_loss: 0.4306 - val_accuracy: 0.8529\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 25s 393ms/step - loss: 0.0749 - accuracy: 0.9842 - val_loss: 0.4283 - val_accuracy: 0.8748\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 26s 400ms/step - loss: 0.0571 - accuracy: 0.9896 - val_loss: 0.3769 - val_accuracy: 0.8787\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 25s 385ms/step - loss: 0.0521 - accuracy: 0.9876 - val_loss: 0.4237 - val_accuracy: 0.8648\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.0430 - accuracy: 0.9906 - val_loss: 0.4965 - val_accuracy: 0.8608\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.0456 - accuracy: 0.9906 - val_loss: 0.6123 - val_accuracy: 0.8350\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.3819 - val_accuracy: 0.8847\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.4025 - val_accuracy: 0.8787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241a92de820>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fine-Tune Training\n",
    "model.fit(train_generator, epochs=30, validation_data=val_generator,\n",
    "          callbacks=[early_stop], class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b4eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 5s 286ms/step - loss: 0.3835 - accuracy: 0.8787\n",
      "Test Accuracy: 87.87%\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "loss, acc = model.evaluate(val_generator)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1039d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "# True labels from validation set\n",
    "y_true = val_generator.classes  \n",
    "\n",
    "# Predicted probabilities\n",
    "y_pred_probs = model.predict(val_generator)\n",
    "\n",
    "# Convert probabilities -> class indices\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57deef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cardboard       0.96      0.81      0.88        80\n",
      "       glass       0.88      0.88      0.88       100\n",
      "       metal       0.81      0.93      0.86        82\n",
      "       paper       0.91      0.95      0.93       118\n",
      "     plastic       0.86      0.86      0.86        96\n",
      "       trash       0.77      0.63      0.69        27\n",
      "\n",
      "    accuracy                           0.88       503\n",
      "   macro avg       0.87      0.84      0.85       503\n",
      "weighted avg       0.88      0.88      0.88       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "class_labels = list(val_generator.class_indices.keys())\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1370a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Begad\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "# # # # Save Model\n",
    "# model.save(\"resnet_model_fixed.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
